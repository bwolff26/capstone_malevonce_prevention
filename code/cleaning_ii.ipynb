{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "818424ba",
   "metadata": {},
   "source": [
    "## Goals\n",
    "\n",
    "So, let us continue the sprucing and finally prepare the dataset for modeling (initially without concern for the other variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "59c73e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import regex as re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a35f2fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39565, 56)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform</th>\n",
       "      <th>text</th>\n",
       "      <th>hate_speech_score</th>\n",
       "      <th>target_race_asian</th>\n",
       "      <th>target_race_black</th>\n",
       "      <th>target_race_latinx</th>\n",
       "      <th>target_race_middle_eastern</th>\n",
       "      <th>target_race_native_american</th>\n",
       "      <th>target_race_pacific_islander</th>\n",
       "      <th>target_race_white</th>\n",
       "      <th>...</th>\n",
       "      <th>target_age_other</th>\n",
       "      <th>target_age</th>\n",
       "      <th>target_disability_physical</th>\n",
       "      <th>target_disability_cognitive</th>\n",
       "      <th>target_disability_neurological</th>\n",
       "      <th>target_disability_visually_impaired</th>\n",
       "      <th>target_disability_hearing_impaired</th>\n",
       "      <th>target_disability_unspecific</th>\n",
       "      <th>target_disability_other</th>\n",
       "      <th>target_disability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>White people are trash.</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You've caught the big gay, it's known to be ai...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm not saying you said that, I'm just saying ...</td>\n",
       "      <td>-1.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Donald Trump. Yeet myself off a building onto ...</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Fabrice Fabrice is ostensibly black or black/l...</td>\n",
       "      <td>-2.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   platform                                               text  \\\n",
       "0         0                            White people are trash.   \n",
       "1         0  You've caught the big gay, it's known to be ai...   \n",
       "2         0  I'm not saying you said that, I'm just saying ...   \n",
       "3         0  Donald Trump. Yeet myself off a building onto ...   \n",
       "4         0  Fabrice Fabrice is ostensibly black or black/l...   \n",
       "\n",
       "   hate_speech_score  target_race_asian  target_race_black  \\\n",
       "0               0.46                0.0                0.0   \n",
       "1               0.03                0.0                0.0   \n",
       "2              -1.29                0.0                1.0   \n",
       "3              -0.24                0.0                0.0   \n",
       "4              -2.84                0.0                1.0   \n",
       "\n",
       "   target_race_latinx  target_race_middle_eastern  \\\n",
       "0                 0.0                         0.0   \n",
       "1                 0.0                         0.0   \n",
       "2                 0.0                         0.0   \n",
       "3                 0.0                         0.0   \n",
       "4                 1.0                         0.0   \n",
       "\n",
       "   target_race_native_american  target_race_pacific_islander  \\\n",
       "0                          0.0                           0.0   \n",
       "1                          0.0                           0.0   \n",
       "2                          0.0                           0.0   \n",
       "3                          0.0                           0.0   \n",
       "4                          0.0                           0.0   \n",
       "\n",
       "   target_race_white  ...  target_age_other  target_age  \\\n",
       "0                1.0  ...               0.0         0.0   \n",
       "1                0.0  ...               0.0         0.0   \n",
       "2                0.0  ...               0.0         0.0   \n",
       "3                0.0  ...               0.0         0.0   \n",
       "4                0.0  ...               0.0         0.0   \n",
       "\n",
       "   target_disability_physical  target_disability_cognitive  \\\n",
       "0                         0.0                          0.0   \n",
       "1                         0.0                          0.0   \n",
       "2                         0.0                          0.0   \n",
       "3                         0.0                          0.0   \n",
       "4                         0.0                          0.0   \n",
       "\n",
       "   target_disability_neurological  target_disability_visually_impaired  \\\n",
       "0                             0.0                                  0.0   \n",
       "1                             0.0                                  0.0   \n",
       "2                             0.0                                  0.0   \n",
       "3                             0.0                                  0.0   \n",
       "4                             0.0                                  0.0   \n",
       "\n",
       "   target_disability_hearing_impaired  target_disability_unspecific  \\\n",
       "0                                 0.0                           0.0   \n",
       "1                                 0.0                           0.0   \n",
       "2                                 0.0                           0.0   \n",
       "3                                 0.0                           0.0   \n",
       "4                                 0.0                           0.0   \n",
       "\n",
       "   target_disability_other  target_disability  \n",
       "0                      0.0                0.0  \n",
       "1                      0.0                0.0  \n",
       "2                      0.0                0.0  \n",
       "3                      0.0                0.0  \n",
       "4                      0.0                0.0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/cleaned_02_i.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0befd1c",
   "metadata": {},
   "source": [
    "https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech <br>\n",
    "hate_speech_score - continuous hate speech measure, where higher = more hateful and lower = less hateful. > 0.5 is approximately hate speech, < -1 is counter or supportive speech, and -1 to +0.5 is neutral or ambiguous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca88a5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    39565.000000\n",
       "mean        -0.943911\n",
       "std          2.073087\n",
       "min         -8.340000\n",
       "25%         -2.330000\n",
       "50%         -0.700000\n",
       "75%          0.570000\n",
       "max          6.300000\n",
       "Name: hate_speech_score, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First up is to rename the hate_speech_score to a more generic label.\n",
    "df['hate_speech_score'].describe() #Again, recall the words copied above fom their website. So, for my purposes I'd be interested\n",
    "#in potentially intervening in people's behaviour. Likely that would start the second category at least at .5;\n",
    "#and we'd still need to figure out the gauge for the IMMEDIATE category.\n",
    "#Part of what might be difficult is the subjectivity in joking and the like.More and more I'm thinking to perhaps go back and\n",
    "#grab those other columns I ignored, such as 'genocide'..... However, for now when we're just doing language we'll work as is\n",
    "#(anyways, i this case I'd rewrite/append to the quoted current source).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "56d6d7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2ed1a756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"OKAY, I'LL LEAVE YOU FUCK YOURSELF LIKE A FUCKING DOG BARKING, BECAUSE I DON'T GIVE A FUCK TO A FUCKING BITCH LIKE YOU! I HOPE YOUR DICK-FACE FALLS ON A PIECE OF CRAP, HAVE A CRAPPY DAY, JACKARSE\""
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i += 1\n",
    "print(df.iloc[i, 2], i)\n",
    "df.iloc[i, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70cd818",
   "metadata": {},
   "source": [
    "### Introducing the first hyperparameter - 'benign', 'concerning', 'malevonent'\n",
    "Corresponding they'll be known as 0, 1, and 2 respectively. However, please note - likely I may tweak these values later. Recall that initialy these 'predictions' are categorical and I'm somewhat artificially assigning such classes to them for my purposes.\n",
    "A further difficulty will be the trend I'v already noticed of 'counter/supportive speach' often being quite graphc as well. Besides fom a NLP point of view making things more difficult, definitionally it would seem to me crass and crude to refer to things in such a boorish manner. Ie perhaps I am biased, however I would hope supportive speach is not as filthy as hate speach, with the only difference being the direction it is aimed at.\n",
    "\n",
    "On the topic of other potential parameters: Pay attention to how I'll also, later on in this section, clean the various texts. Perhaps it'll be worthwhile to experiment with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f5d0db22",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_limit, upper_limit = -1, 2 #1.41 makes the two big groups approx. equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5845629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hate_rank'] = [2 if i > upper_limit\n",
    "                  else 1 if i > lower_limit else 0\n",
    "                  for i in df['hate_speech_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f107f61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hate_rank\n",
       "1    0.503627\n",
       "0    0.443650\n",
       "2    0.052723\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hate_rank'].value_counts(normalize=True) #Hmm, eh whatever - we'll keep it at this propotion for now.\n",
    "#To write it out in a comment here,in case I change it later: .44,.5, .06 resp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8f704152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hmm, something else I noticed while going through posts is the useage of capitals. Perhaps we should go ahead and make a\n",
    "#contains lots of capitals column:\n",
    "samp = \"OKAY, I'LL LEAVE YOU FUCK YOURSELF LIKE A FUCKING DOG BARKING, BECAUSE I DON'T GIVE A FUCK TO A FUCKING BITCH LIKE YOU! I HOPE YOUR DICK-FACE FALLS ON A PIECE OF CRAP, HAVE A CRAPPY DAY, JACKARSE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e69e4dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capital_checker(sentance, thresh=.2):\n",
    "    count, per_count = 0, 0\n",
    "    for i in range(len(sentance)):\n",
    "        if sentance[i].isupper() == True:\n",
    "            count += 1\n",
    "        if sentance[i] == '.':\n",
    "            per_count += 1\n",
    "    if (count - per_count)/len(sentance) >= thresh and count > per_count: #Ie the sentance has an overwhelming capital presence...\n",
    "        verdict = 1\n",
    "    else:\n",
    "        verdict = 0\n",
    "    return verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "15ff1453",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['capital_sentance'] = df['text'].apply(capital_checker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "e82bbe3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "capital_sentance\n",
       "0    0.966056\n",
       "1    0.033944\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['capital_sentance'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "4877b35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Great, now we can move foreward with NLPing, finally.Pragmatically it might be worthwhile to playaround with not lowercasing\n",
    "#the words, but for now we'll go with the 'default' approach of doing so, in an attempt to reduce the upcoming flood of featues.\n",
    "\n",
    "#While I'm doing all this, I might as well make a word counter as well. That might be useful later.\n",
    "\n",
    "#Hmm, let's start by breaking apart the comments, trying to get an aveage word count...\n",
    "def document_words(raw_document):\n",
    "\n",
    "    #Remove some various html hiccups that may have crept in.\n",
    "    document_text = BeautifulSoup(raw_document).get_text()\n",
    "    \n",
    "    #Further purge it via regex to keep only characters per Regex. For sure in this case I'm keeping numbers\n",
    "    letters_only = re.sub(\"[^a-zA-Z0-9]\", \" \", document_text)\n",
    "    #Convert to lower case, split into individual words.\n",
    "    \n",
    "    words = letters_only.split()\n",
    "    words = [w.lower() for w in words]\n",
    " \n",
    "    p_stemmer = PorterStemmer()\n",
    "    stemmed_words = [p_stemmer.stem(i, to_lowercase=False) for i in words]\n",
    "    \n",
    "    #And finally, let us merge back everything to a new document.\n",
    "    return(\" \".join(stemmed_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "0e1b38c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bwolf\\AppData\\Local\\Temp\\ipykernel_14960\\3250074403.py:10: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  document_text = BeautifulSoup(raw_document).get_text()\n"
     ]
    }
   ],
   "source": [
    " df['cleaned_text'] = df['text'].apply(document_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "ab266b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['wc_cleaned_text'] =  df['cleaned_text'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "6cbc643e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    39565.000000\n",
       "mean        25.779932\n",
       "std         20.312349\n",
       "min          1.000000\n",
       "25%         11.000000\n",
       "50%         20.000000\n",
       "75%         35.000000\n",
       "max        128.000000\n",
       "Name: wc_cleaned_text, dtype: float64"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['wc_cleaned_text'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a367b25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hate_rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17553.0</td>\n",
       "      <td>28.759528</td>\n",
       "      <td>21.745569</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>40.00</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19926.0</td>\n",
       "      <td>23.293938</td>\n",
       "      <td>18.695904</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>32.00</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2086.0</td>\n",
       "      <td>24.454458</td>\n",
       "      <td>19.301883</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>32.75</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count       mean        std  min   25%   50%    75%    max\n",
       "hate_rank                                                              \n",
       "0          17553.0  28.759528  21.745569  1.0  13.0  23.0  40.00  128.0\n",
       "1          19926.0  23.293938  18.695904  2.0  10.0  18.0  32.00  124.0\n",
       "2           2086.0  24.454458  19.301883  2.0  10.0  19.0  32.75  117.0"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('hate_rank')['wc_cleaned_text'].describe()#Hmm, pehaps there is a trend here afterall - 0 is longer on\n",
    "#all fronts. Ie perhaps when one uses words more, as opposed to being rash and simply labeling things in a smaller word insult\n",
    "#that can be easily digested, that is a sign of a more nuanced person. However,such differences are negligible so perhaps\n",
    "#it is not all that significant. Regardless, we continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "25232a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hmm, yeah, I guess we'll export these\n",
    "df.to_csv('../data/cleaned_02_ii.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcc4ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f62542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a6aefc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
